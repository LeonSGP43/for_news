import { GoogleGenAI, type ThinkingLevel } from '@google/genai'

let ai: GoogleGenAI | null = null

function getAI(): GoogleGenAI {
  if (!ai) {
    const apiKey = process.env.GEMINI_API_KEY
    if (!apiKey) {
      throw new Error('GEMINI_API_KEY is not set')
    }
    console.log('ğŸ¤– Initializing Gemini AI...')
    ai = new GoogleGenAI({ apiKey })
  }
  return ai
}

// æ·±åº¦åˆ†ææ¨¡å‹é…ç½® (gemini-3-pro-preview with thinking)
const analysisConfig = {
  thinkingConfig: {
    thinkingLevel: 'high' as ThinkingLevel
  }
}

// å¿«é€Ÿé—®ç­”æ¨¡å‹é…ç½®
const chatConfig = {
  thinkingConfig: {
    thinkingLevel: 'low' as ThinkingLevel
  }
}

interface TokenUsage {
  promptTokens: number
  responseTokens: number
  thinkingTokens: number
  totalTokens: number
}

function logTokenUsage(model: string, usage: TokenUsage) {
  console.log(`ğŸ“Š [${model}] Tokenæ¶ˆè€—: è¾“å…¥=${usage.promptTokens} è¾“å‡º=${usage.responseTokens} æ€è€ƒ=${usage.thinkingTokens} æ€»è®¡=${usage.totalTokens}`)
}

export async function generateAnalysis(prompt: string): Promise<string> {
  const response = await getAI().models.generateContentStream({
    model: 'gemini-3-pro-preview',
    config: analysisConfig,
    contents: [{
      role: 'user',
      parts: [{ text: prompt }]
    }]
  })

  let result = ''
  let usageMetadata: unknown = null
  
  for await (const chunk of response) {
    result += chunk.text || ''
    if (chunk.usageMetadata) {
      usageMetadata = chunk.usageMetadata
    }
  }
  
  // æ‰“å°tokenæ¶ˆè€—
  if (usageMetadata) {
    const meta = usageMetadata as Record<string, number>
    logTokenUsage('gemini-3-pro', {
      promptTokens: meta.promptTokenCount || 0,
      responseTokens: meta.candidatesTokenCount || 0,
      thinkingTokens: meta.thoughtsTokenCount || 0,
      totalTokens: meta.totalTokenCount || 0
    })
  }
  
  return result
}

export async function generateChat(prompt: string): Promise<string> {
  const response = await getAI().models.generateContentStream({
    model: 'gemini-2.5-flash',
    contents: [{
      role: 'user',
      parts: [{ text: prompt }]
    }]
  })

  let result = ''
  let usageMetadata: unknown = null
  
  for await (const chunk of response) {
    result += chunk.text || ''
    if (chunk.usageMetadata) {
      usageMetadata = chunk.usageMetadata
    }
  }
  
  // æ‰“å°tokenæ¶ˆè€—
  if (usageMetadata) {
    const meta = usageMetadata as Record<string, number>
    logTokenUsage('gemini-2.5-flash', {
      promptTokens: meta.promptTokenCount || 0,
      responseTokens: meta.candidatesTokenCount || 0,
      thinkingTokens: meta.thoughtsTokenCount || 0,
      totalTokens: meta.totalTokenCount || 0
    })
  }
  
  return result
}

export function buildNewsContext(articles: unknown[]): string {
  // å‹ç¼©JSONï¼Œæ— ç©ºæ ¼æ— æ¢è¡Œ
  return JSON.stringify(articles)
}

export const SYSTEM_PROMPT = `ä½ æ˜¯èˆ†æƒ…åˆ†æåŠ©æ‰‹ã€‚åŸºäºæä¾›çš„æ–°é—»æ•°æ®å›ç­”é—®é¢˜ã€‚
è§„åˆ™ï¼š1.åªåŸºäºæ•°æ®å›ç­”,ä¸ç¼–é€  2.æ— ç›¸å…³ä¿¡æ¯æ—¶æ˜ç¡®è¯´æ˜ 3.å¼•ç”¨æ—¶æä¾›æ ‡é¢˜ 4.ä¸­æ–‡å›ç­” 5.ç®€æ´æœ‰æ¡ç†
æ•°æ®å­—æ®µï¼št=æ ‡é¢˜,d=æè¿°,r=æ’å(æ•°å­—è¶Šå°è¶Šçƒ­),s=æ¿å—/å¹³å°`
